{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method,scores in data:\n",
    "    visualise_metrics(scores)\n",
    "\n",
    "    l = ['A','Z']\n",
    "{i : name for i,name in enumerate(l)}\n",
    "\n",
    "def visualise_clusters(vectorised_input, label_names, ):\n",
    "\n",
    "    dist = 1 - cosine_similarity(vectorised_input)\n",
    "\n",
    "    # Use multidimensional scaling to convert the dist matrix into a 2-dimensional array \n",
    "\n",
    "    MDS()\n",
    "\n",
    "    # n_components=2 to plot results in a two-dimensional plane\n",
    "    # \"precomputed\" because the  distance matrix dist is already computed\n",
    "    # `random_state` set to 0 so that the plot is reproducible.\n",
    "    mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=0)\n",
    "\n",
    "    pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
    "\n",
    "    xs, ys = pos[:, 0], pos[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    #set up colors per clusters using a dict\n",
    "    # #1b9e77 (green) #d95f02 (orange) #7570b3 (purple) #e7298a (pink)\n",
    "    colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#000000'}\n",
    "\n",
    "    \n",
    "    #set up cluster names using a dict\n",
    "    cluster_names = {i = name for i,name in enumerate(label_names)}\n",
    "    cluster_colors = {colors[i] for i in cluster_names.keys()}\n",
    "\n",
    "    #create data frame that has the result of the MDS plus the cluster numbers and titles\n",
    "    df = pd.DataFrame(dict(x=xs, y=ys, label=cluster_names))\n",
    "\n",
    "    #group by cluster\n",
    "    groups = df.groupby('label')\n",
    "\n",
    "    # set up plot\n",
    "    fig, ax = plt.subplots(figsize=(17, 9)) # set size\n",
    "    ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "\n",
    "    #iterate through groups to layer the plot\n",
    "    #note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
    "    for name, group in groups:\n",
    "        ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, \n",
    "                label=cluster_names[name], \n",
    "                color=cluster_colors[name], \n",
    "                mec='none')\n",
    "        ax.set_aspect('auto')\n",
    "        ax.tick_params(\\\n",
    "            axis= 'x',          # changes apply to the x-axis\n",
    "            which='both',      # both major and minor ticks are affected\n",
    "            bottom=False,      # ticks along the bottom edge are off\n",
    "            top=False,         # ticks along the top edge are off\n",
    "            labelbottom=False)\n",
    "        ax.tick_params(\\\n",
    "            axis= 'y',         # changes apply to the y-axis\n",
    "            which='both',      # both major and minor ticks are affected\n",
    "            left=False,      # ticks along the bottom edge are off\n",
    "            top=False,         # ticks along the top edge are off\n",
    "            labelleft=False)\n",
    "        \n",
    "        ax.legend(numpoints=1)  #show legend with only 1 point\n",
    "            \n",
    "            \n",
    "            plt.show() #show the plot\n",
    "        \n",
    "        linkage_matrix = ward(dist) #define the linkage_matrix using ward clustering pre-computed distances\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 20)) # set size\n",
    "        ax = dendrogram(linkage_matrix, orientation=\"right\");\n",
    "        plt.tick_params(\\\n",
    "            axis= 'x',          # changes apply to the x-axis\n",
    "            which='both',      # both major and minor ticks are affected\n",
    "            bottom=False,      # ticks along the bottom edge are off\n",
    "            top=False,         # ticks along the top edge are off\n",
    "            labelbottom=False)\n",
    "\n",
    "        plt.tight_layout() #show plot with tight layout\n",
    "\n",
    "        #uncomment below to save figure\n",
    "        plt.savefig('ward_clusters.png', dpi=200) #save figure as ward_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token to index dictionary is already in the tfidf model \n",
    "token2idx = tfidf_vectorizer.vocabulary_ \n",
    "# inverse of the dictionary \n",
    "idx2token = {v: k for k, v in token2idx.items()} \n",
    "  \n",
    "# clf.coef_ yields matrix with classes as rows and tokens/features as columns \n",
    "# we don't have access to anything else, so we retrieve tokens weights from the inverse of this matrix \n",
    "idx2weight = {i: weight for i, weight in enumerate(clf.coef_.T)} \n",
    "#weight : vector of size 5  \n",
    " \n",
    "top_n = 6 \n",
    "  \n",
    "# argsort on the clf.coef_ sorts each row (axis=1) increasingly and yields indices instead of the actual values \n",
    "argsorted_cls = np.argsort(clf.coef_, axis=1) \n",
    "# argsorted_cls: matrix of size C X D (C: number of classes, D: number of features) \n",
    "  \n",
    "# we loop over the obtained, sorted indices, keeping the index number (representing the class index) \n",
    "for class_index, sorted_tokens in enumerate(argsorted_cls): \n",
    "    # using idx2target we can obtain classes actual name \n",
    "    print(f\"Class {idx2token[class_index]} ({class_index}) and it's top {top_n} tokens:\")\n",
    "     \n",
    "    # we need to inverse the obtained indices from the argsorted_cls, to make it decreasing \n",
    "    # we are interested in top 6 results \n",
    "    for token in sorted_tokens[::-1][:top_n]:  \n",
    "        # we can use idx2weight to obtain back the token's weight \n",
    "        # from this we can check and verify both: \n",
    "        #   1) tokens are really ranked from top 1 to top 6 \n",
    "        #   2) among classes, the highest value is being assigned to the class \n",
    "        #      to which the token has been located at as the top one \n",
    "        reformatted_weights = ', '.join([f\"{x:.4f}\" for x in idx2weight[token].tolist()]) \n",
    "        # idx2token allows us to obtain the token's actual name \n",
    "        print(f\"Token {idx2token[token]} ({token}) has a weight:\\n\\t[{reformatted_weights}]\") \n",
    "    print() "
   ]
  }
 ]
}