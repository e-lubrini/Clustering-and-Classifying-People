{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python39264bit4b96a5d0423d4999bcdcb027060416b6",
   "display_name": "Python 3.9.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Creating the corpus\n",
    "* Extracting a text corpus from Wikipedia made of plain text sentences\n",
    "* selected so as to have a roughly balanced corpus in terms of training data (each target category should be associated with the same number of sentences). \n",
    "\n",
    "* Including 6 categories:\n",
    "architects, mathematicians, painters, politicians, singers and writers.\n",
    "\n",
    "***\n",
    "\n",
    "* SCRIPT INPUT:\n",
    "    \n",
    "    * a number k of persons per category\n",
    "\n",
    "    * a number n of sentences per person\n",
    "    (persons whose wikipedia description is too short to have n sentences, should be ignored). \n",
    "\n",
    "* SCRIPT OUTPUT:\n",
    "\n",
    "    * the text of the corresponding Wikipedia page\n",
    "    \n",
    "    * the corresponding data type (A or Z) and category\n",
    "    \n",
    "    * WikiData description\n",
    "    \n",
    "            ▶ Store these into a csv or a json file and save it on your hard drive"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Part 1\n",
    "Create a list of persons you want to work with. Those persons\n",
    "should fall into two main types: artists (A) and non artists (Z).\n",
    "Singers, writers and painters are of type A while architects, politicians and mathematicians of type Z. For each category, select 30\n",
    "persons of that category. So in total you should have a list of 180\n",
    "persons (half of them are artists and half of them are not).\n",
    "You can use the wikidata warehouse to find persons of the expected categories. More precisely, the Wikidata collection can be\n",
    "filtered out using the SPARQL language and the following endpoint: https://query.wikidata.org/.\n",
    "You can thus use the SPARQLwrapper python library to apply a\n",
    "SPARQL query to the Wikidata warehouse and retrieve the required item identifiers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import wikipedia\n",
    "from random import Random\n",
    "from spacy.lang.en import English\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store wiki list pages\n",
    "wiki_pages = {}\n",
    "wiki_pages['singer'] = wikipedia.page('List of singers')\n",
    "wiki_pages['writer'] = wikipedia.page('List of writers')\n",
    "wiki_pages['painter'] = wikipedia.page('List of painters')\n",
    "wiki_pages['architect'] = wikipedia.page('List of architects')\n",
    "wiki_pages['politician'] = wikipedia.page('List of politicians by nationality')\n",
    "wiki_pages['mathematician'] =  wikipedia.page('List of mathematicians')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_article_keyword(wiki_page):\n",
    "    #if article\n",
    "    \n",
    "\n",
    "    #if list\n",
    "    keyword = wiki_page.title #after list(s) of\n",
    "    for category in wiki_page.categories:\n",
    "        if keyword in category:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordArticleChecker:\n",
    "    def __init__(self,keyword):\n",
    "        self.keyword = keyword\n",
    "\n",
    "    def __call__(self,wiki_page):\n",
    "        for category in wiki_page.categories:\n",
    "            if self.keyword in category:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_list_keyword(wiki_page):\n",
    "    \n",
    "    if keyword in wiki_page.title:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_is_not_list(wiki_page):   \n",
    "    for category in wiki_page.categories:\n",
    "        if category.lower().startswith('list'):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_from_dic(wiki_page, \n",
    "                            n_articles,\n",
    "                            page_filter=lambda x: True,\n",
    "                            check_is_final_node=check_is_not_list,\n",
    "                            rng=Random(),\n",
    "                            max_depth = 7,\n",
    "                            _memory=None):\n",
    "\n",
    "    print('  Checking:', wiki_page.title)\n",
    "    # if the function is being called for the first time, assign an empty set \n",
    "    if _memory is None:\n",
    "        _memory = set()\n",
    "\n",
    "    # trivial cases:\n",
    "    # if the number of articles retrieved satisfies the request\n",
    "    # or the current wiki_page has already been visited\n",
    "    # return an empty list\n",
    "    if (wiki_page.title in _memory \n",
    "        or n_articles <= 0\n",
    "        or not page_filter(wiki_page)\n",
    "        or max_depth == 0):\n",
    "        return []\n",
    "\n",
    "    # if the page has not been visited yet, add it to the _memory\n",
    "    _memory.add(wiki_page.title)\n",
    "\n",
    "    # if the wiki_page is an article (not a list),\n",
    "    # return it \n",
    "    if check_is_final_node(wiki_page):\n",
    "        print('▶ Added to list:',wiki_page.title)\n",
    "        return [wiki_page]\n",
    "    \n",
    "    # else, the page is a list\n",
    "    else:\n",
    "        articles = []\n",
    "        # shuffle the links of the list\n",
    "        while n_articles > 0:\n",
    "            title = rng.choices(wiki_page.links, k=1)   \n",
    "            try:\n",
    "                page = wikipedia.page(title)\n",
    "            except wikipedia.exceptions.WikipediaException:\n",
    "                continue\n",
    "\n",
    "            # get articles from the list links and add them to the list of articles\n",
    "            local_articles = get_articles_from_list(wiki_page=page, \n",
    "                                                    n_articles=1, \n",
    "                                                    page_filter=page_filter,\n",
    "                                                    check_is_final_node=check_is_final_node,\n",
    "                                                    rng=rng,\n",
    "                                                    max_depth = max_depth-1,\n",
    "                                                    _memory=_memory)\n",
    "            articles.extend(local_articles)\n",
    "\n",
    "            n_articles -= len(local_articles)\n",
    "\n",
    "            # if the number of articles retrieved satisfies the request\n",
    "            # return the articles\n",
    "            if n_articles == 0:\n",
    "                return articles\n",
    "            elif n_articles < 0:\n",
    "                return articles[:n_articles]\n",
    "\n",
    "        return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Checking: Lists of singers\n",
      "  Checking: List of scat singers\n",
      "  Checking: Nikki Yanofsky\n",
      "▶ Added to list: Nikki Yanofsky\n",
      "  Checking: List of Nepalese singers\n",
      "  Checking: Karna Das\n",
      "▶ Added to list: Karna Das\n",
      "  Checking: List of Romanian singers\n",
      "  Checking: Joseph Schmidt\n",
      "▶ Added to list: Joseph Schmidt\n",
      "  Checking: Lists of writers\n",
      "  Checking: List of poetry awards\n",
      "  Checking: List of early-modern women playwrights (UK)\n",
      "  Checking: Frances Brooke\n",
      "▶ Added to list: Frances Brooke\n",
      "  Checking: List of French-language authors\n",
      "  Checking: Jean du Vergier de Hauranne\n",
      "  Checking: Henri Michaux\n",
      "▶ Added to list: Henri Michaux\n",
      "  Checking: List of historical novelists\n",
      "  Checking: List of Hebrew-language authors\n",
      "  Checking: List of Hebrew-language playwrights\n",
      "  Checking: List of Hebrew-language poets\n",
      "  Checking: Solomon ibn Gabirol\n",
      "▶ Added to list: Solomon ibn Gabirol\n",
      "  Checking: Lists of painters\n",
      "  Checking: Plastic arts\n",
      "  Checking: Model (art)\n",
      "  Checking: List of Carlo Maratta pupils and assistants\n",
      "  Checking: Filippo Tancredi\n",
      "▶ Added to list: Filippo Tancredi\n",
      "  Checking: List of art magazines\n",
      "  Checking: Académie des Beaux-Arts\n",
      "  Checking: New media art\n",
      "  Checking: Cultural policy\n",
      "  Checking: List of Nihonga painters\n",
      "  Checking: Yuki Ogura\n",
      "▶ Added to list: Yuki Ogura\n",
      "  Checking: Sculpture trail\n",
      "  Checking: List of art magazines\n",
      "  Checking: Conservator-restorer\n",
      "  Checking: Lists of painters by nationality\n",
      "  Checking: List of Spanish painters\n",
      "  Checking: Esteban Márquez de Velasco\n",
      "▶ Added to list: Esteban Márquez de Velasco\n",
      "  Checking: List of architects\n",
      "  Checking: Roger Taillibert\n",
      "▶ Added to list: Roger Taillibert\n",
      "  Checking: Paulo Mendes da Rocha\n",
      "▶ Added to list: Paulo Mendes da Rocha\n",
      "  Checking: Hippodamus of Miletus\n",
      "▶ Added to list: Hippodamus of Miletus\n",
      "  Checking: List of foreign-born United States politicians\n",
      "  Checking: The Church of Jesus Christ of Latter-day Saints\n",
      "  Checking: Scotland\n",
      "  Checking: Joseph Henry Burrows\n",
      "▶ Added to list: Joseph Henry Burrows\n",
      "  Checking: Governor of New Jersey\n",
      "  Checking: Louisiana Supreme Court\n",
      "  Checking: John Quinn (New York politician)\n",
      "▶ Added to list: John Quinn (New York politician)\n",
      "  Checking: Solicitor General of Texas\n",
      "  Checking: Lieutenant Governor of North Dakota\n",
      "  Checking: List of presidents of the Maine Senate\n",
      "  Checking: Thomaston, Maine\n",
      "  Checking: Jay Cutler\n",
      "  Checking: Forrest Goodwin\n",
      "▶ Added to list: Forrest Goodwin\n",
      "  Checking: Lists of mathematicians\n",
      "  Checking: List of statisticians\n",
      "  Checking: Prasanta Chandra Mahalanobis\n",
      "▶ Added to list: Prasanta Chandra Mahalanobis\n",
      "  Checking: List of Russian mathematicians\n",
      "  Checking: Rigged Hilbert space\n",
      "  Checking: List of Russian chess players\n",
      "  Checking: Krawtchouk matrices\n",
      "  Checking: Pontryagin class\n",
      "  Checking: Goppa code\n",
      "  Checking: List of Russian-language playwrights\n",
      "  Checking: List of presidents of Russia\n",
      "  Checking: Steklov Institute of Mathematics\n",
      "  Checking: List of Russian biologists\n",
      "  Checking: Geometry\n",
      "  Checking: Pafnuty Chebyshev\n",
      "▶ Added to list: Pafnuty Chebyshev\n",
      "  Checking: List of films about mathematicians\n",
      "  Checking: List of Indian mathematicians\n",
      "  Checking: Varāhamihira\n",
      "▶ Added to list: Varāhamihira\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'singer': [<WikipediaPage 'Nikki Yanofsky'>,\n",
       "  <WikipediaPage 'Karna Das'>,\n",
       "  <WikipediaPage 'Joseph Schmidt'>],\n",
       " 'writer': [<WikipediaPage 'Frances Brooke'>,\n",
       "  <WikipediaPage 'Henri Michaux'>,\n",
       "  <WikipediaPage 'Solomon ibn Gabirol'>],\n",
       " 'painter': [<WikipediaPage 'Filippo Tancredi'>,\n",
       "  <WikipediaPage 'Yuki Ogura'>,\n",
       "  <WikipediaPage 'Esteban Márquez de Velasco'>],\n",
       " 'architect': [<WikipediaPage 'Roger Taillibert'>,\n",
       "  <WikipediaPage 'Paulo Mendes da Rocha'>,\n",
       "  <WikipediaPage 'Hippodamus of Miletus'>],\n",
       " 'politician': [<WikipediaPage 'Joseph Henry Burrows'>,\n",
       "  <WikipediaPage 'John Quinn (New York politician)'>,\n",
       "  <WikipediaPage 'Forrest Goodwin'>],\n",
       " 'mathematician': [<WikipediaPage 'Prasanta Chandra Mahalanobis'>,\n",
       "  <WikipediaPage 'Pafnuty Chebyshev'>,\n",
       "  <WikipediaPage 'Varāhamihira'>]}"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "wiki_keywords_people = {}\n",
    "for k,v in wiki_pages.items():\n",
    "    wiki_keywords_people[k] = get_articles_from_dic(wiki_page=v,\n",
    "                                        n_articles=3, \n",
    "                                        page_filter=KeywordArticleChecker(k),\n",
    "                                        rng=Random(0))\n",
    "wiki_keywords_people"
   ]
  },
  {
   "source": [
    "## Part 2\n",
    "for each selected person, retrieve his.her Wikidata description and\n",
    "Wikipedia page title. This can be done using the wikidata API\n",
    "along with the wptools python library.\n",
    "Once you have a list of wikipedia page titles, fetch (if it exists) the corresponding English wikipedia page, and extract the n first sentences of its content."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacySentenceTokenizer:\n",
    "    def __init__(self, nlp=English()):\n",
    "        self.nlp = nlp\n",
    "        nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "\n",
    "    def __call__(self, txt):\n",
    "        return self.nlp(txt).sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles_descriptions_sentences(wiki_page : wikipedia.WikipediaPage,\n",
    "                                        n_sentences,\n",
    "                                        sentence_tokenize=SpacySentenceTokenizer()):\n",
    "    \n",
    "    title = wiki_page.title\n",
    "    description = wiki_page.summary # TODO: wikidata\n",
    "    content = wiki_page.content\n",
    "    sentences = [sent.string.strip() for sent in islice(sentence_tokenize(content), n_sentences)]\n",
    "    \n",
    "    return (title, description, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for k,v in wiki_keywords_people.items():\n",
    "    data[k] = []\n",
    "    for page in v:\n",
    "        article = {}\n",
    "        t,d,s = get_titles_descriptions_sentences(page, 10)\n",
    "        article['title'] = t\n",
    "        article['description'] = d\n",
    "        article['sentences'] = s\n",
    "        data[k].append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'title': 'Nikki Yanofsky',\n",
       "  'description': 'Nicole Rachel \"Nikki\" Yanofsky (born February 8, 1994) is a jazz-pop singer from Montreal, Quebec. She sang the CTV Olympic broadcast theme song, \"I Believe\", which was also the theme song of the 2010 Winter Olympic Games. She also performed at the opening and closing ceremonies for the Olympics and at the opening ceremony of the 2010 Winter Paralympic Games. She has released three studio albums to date, including Nikki in 2010, Little Secret in 2014, and Turn Down the Sound in 2020.',\n",
       "  'sentences': ['Nicole Rachel \"Nikki\" Yanofsky (born February 8, 1994) is a jazz-pop singer from Montreal, Quebec.',\n",
       "   'She sang the CTV Olympic broadcast theme song, \"I Believe\", which was also the theme song of the 2010 Winter Olympic Games.',\n",
       "   'She also performed at the opening and closing ceremonies for the Olympics and at the opening ceremony of the 2010 Winter Paralympic Games.',\n",
       "   'She has released three studio albums to date, including Nikki in 2010, Little Secret in 2014, and Turn Down the Sound in 2020.',\n",
       "   '== Recordings ==\\nYanofsky recorded the Ella Fitzgerald song \"Air Mail Special\" for Verve Records and it was released in June 2007 on the album We All Love Ella:',\n",
       "   'Celebrating the First Lady of Song.',\n",
       "   'Produced by Tommy LiPuma, this track made Yanofsky the youngest singer to record for Verve.',\n",
       "   'She then recorded \"Gotta Go My Own Way\" in English and French for the movie High School Musical 2.',\n",
       "   'She collaborated with Herbie Hancock and will.i.am on a crossover version of the swing era hit \"Stompin\\' at the Savoy\".',\n",
       "   \"It was released on Kareem Abdul-Jabbar's audio book, On the Shoulders of Giants.\"]},\n",
       " {'title': 'Karna Das',\n",
       "  'description': 'Karna Das (Nepali: कर्ण दास) (born 24 November 1974 in Pokhara, Nepal), is a Nepali musician, singer, songwriter, lyricist, composer, and record producer. Das is regarded as the \"living legend\" of the Nepali music landscape. He is revered for his soothing and melodious timbre and also for his distinct songwriting attributed with immense depth and earnestness. His lyrics spans topics such as philosophical and existential issues of mankind, perseverance, overcoming ordeals, lamentation, hope, anti-fatalism, and patriotism.He completed high school in 1993, completed his Intermediate of Arts (IA) in Education, and studied economics in college. Das was the lead vocalist of the band Madhyanha (\"Central Point\"). He began his singing career in 1997 with the band\\'s first song, \"Jindagi Ko Ke Bharosa\". Das wrote the song and furnished it with his vocals, at the age of 20.Das plays piano, guitar, and bass guitar. His musical inspirations include Elton John, Richard Michael, Scorpions, Michael Jackson, Gulam Ali of Pakistan, Lata Mangeshkar and the Ghazal singer Jagjit Singh of India, and Narayan Gopal of Nepal.Das makes rare appearances in commercial and popular media.',\n",
       "  'sentences': ['Karna Das (Nepali:',\n",
       "   'कर्ण दास) (born 24 November 1974 in Pokhara, Nepal), is a Nepali musician, singer, songwriter, lyricist, composer, and record producer.',\n",
       "   'Das is regarded as the \"living legend\" of the Nepali music landscape.',\n",
       "   'He is revered for his soothing and melodious timbre and also for his distinct songwriting attributed with immense depth and earnestness.',\n",
       "   'His lyrics spans topics such as philosophical and existential issues of mankind, perseverance, overcoming ordeals, lamentation, hope, anti-fatalism, and patriotism.',\n",
       "   'He completed high school in 1993, completed his Intermediate of Arts (IA) in Education, and studied economics in college.',\n",
       "   'Das was the lead vocalist of the band Madhyanha (\"Central Point\").',\n",
       "   'He began his singing career in 1997 with the band\\'s first song, \"Jindagi Ko Ke Bharosa\".',\n",
       "   'Das wrote the song and furnished it with his vocals, at the age of 20.Das plays piano, guitar, and bass guitar.',\n",
       "   'His musical inspirations include Elton John, Richard Michael, Scorpions, Michael Jackson, Gulam Ali of Pakistan, Lata Mangeshkar and the Ghazal singer Jagjit Singh of India, and Narayan Gopal of Nepal.']},\n",
       " {'title': 'Joseph Schmidt',\n",
       "  'description': 'Joseph Schmidt (March 4, 1904 – November 16, 1942) was an Austro-Hungarian and Romanian Jewish tenor and actor. He was born in Davideny (Ukrainian: Davydivka) village in the Storozhynets district of the Bukovina province of Austria-Hungary, which became part of Romania after World War I and is now part of Ukraine.\\n\\n',\n",
       "  'sentences': ['Joseph Schmidt (March 4, 1904 – November 16, 1942) was an Austro-Hungarian and Romanian Jewish tenor and actor.',\n",
       "   'He was born in Davideny (Ukrainian:',\n",
       "   'Davydivka) village in the Storozhynets district of the Bukovina province of Austria-Hungary, which became part of Romania after World War I and is now part of Ukraine.',\n",
       "   '== Life and career ==\\nIn addition to German, which was his first language, and Yiddish, he learned Hebrew and became fluent in Romanian, French and English.',\n",
       "   'His first vocal training was as a boy alto in the Czernowitz Synagogue.',\n",
       "   'His talents were quickly recognised and by 1924 he was featured in his first solo recital in Czernowitz singing traditional Jewish songs and arias by Verdi, Puccini, Rossini and Bizet.',\n",
       "   'Soon he moved to Berlin and took piano and singing lessons from Professor Hermann Weißenborn at the Königliche Musikschule.',\n",
       "   'He returned to Romania for his military service.',\n",
       "   \"In 1929, he went back to Berlin, where Cornelis Bronsgeest, a famous Dutch baritone, engaged him for a radio broadcast as Vasco da Gama in Meyerbeer's L'Africaine.\",\n",
       "   'This was the beginning of a successful international career.']}]"
      ]
     },
     "metadata": {},
     "execution_count": 194
    }
   ],
   "source": [
    "data['singer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split categories\n",
    "A = ['singer', 'writer', 'painter']\n",
    "Z = ['architect', 'politician', 'mathematician']\n",
    "\n",
    "A_cat = {a:data[a] for a in A}\n",
    "\n",
    "Z_cat = {z:data[z] for z in Z}\n",
    "\n",
    "data = {'A':A_cat, 'Z':Z_cat}"
   ]
  },
  {
   "source": [
    "## part 3\n",
    "Save data for preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ]
}