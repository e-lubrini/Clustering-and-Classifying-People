{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Preprocessing\n",
    "* For each Wikipedia text and Wikidata description collected:\n",
    "\n",
    "    tokenise the text, lowercase the tokens, remove function words\n",
    "\n",
    "* Store the results in a pandas dataframe containing 5 columns:\n",
    "\n",
    "    person, Wikipedia page text, Wikipedia page text after preprocessing, Wikidata description, Wikidata description after preprocessing\n",
    "\n",
    "Note. To improve clustering and classification results, feel free to\n",
    "add further pre-processing steps (eg Named entity recognition, postagging and extraction of e.g., nouns and verbs)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/elisa/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_tokenize(string):\n",
    "    # Sentence splitting\n",
    "    sentences = nltk.sent_tokenize(string)\n",
    "    \n",
    "    # tokenizing \n",
    "    tokenised_s = list(map(nltk.word_tokenize, sentences))\n",
    "\n",
    "    return tokenised_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    \n",
    "    # tokenizing \n",
    "    tokenised_s = nltk.word_tokenize(sent)\n",
    "\n",
    "    #print('Tokenised:', tokenised_s)\n",
    "\n",
    "    return tokenised_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a translation table that maps each punctuation sign to the empty string\n",
    "punct_removed = str.maketrans('','',string.punctuation)\n",
    "\n",
    "# Define a function which segments, tokenizes and removes punctuation signs\n",
    "def tokenize_no_punct(s):\n",
    "    \n",
    "    s = s.translate(punct_removed)\n",
    "\n",
    "    # tokenizing \n",
    "    tokenised_s = segment_and_tokenize(s)\n",
    "\n",
    "    #print('Tokenised without punctuation:', tokenised_s[:10])\n",
    "\n",
    "    return tokenised_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case tokens and remove punctuation\n",
    "\n",
    "def lower_case(c):\n",
    "    return tokenize_no_punct(c.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove function words\n",
    "\n",
    "def preprocess(c):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    lower_s = lower_case(c)\n",
    "\n",
    "    no_stopw_c = [t for s in lower_s for t in s if t not in stop_words]\n",
    "\n",
    "    #print('Preprocessed: ', no_stopw_c[:10])\n",
    "\n",
    "    return no_stopw_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "▶ cat: A\n",
      "▶ keyw: singer\n",
      "▶ keyw: writer\n",
      "▶ keyw: painter\n",
      "▶ cat: Z\n",
      "▶ keyw: architect\n",
      "▶ keyw: politician\n",
      "▶ keyw: mathematician\n"
     ]
    }
   ],
   "source": [
    "with open('data/data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for cat,v in data.items():\n",
    "    print('▶ cat:', cat)\n",
    "    for keyw,articles in v.items():\n",
    "        print('▶ keyw:', keyw)\n",
    "        for art in articles:\n",
    "            art['p_content'] = []\n",
    "            try: # TODO BLOCK NONEs IN CORPUS EXTRACTION\n",
    "                art['p_description'] = preprocess(art['description'])\n",
    "            except AttributeError:\n",
    "                art['p_description'] = None\n",
    "            art['p_content'].append(preprocess(art['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['bulgarian', 'popfolk', 'musician']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "data['A']['singer'][0]['p_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# store in a dataframe\n",
    "#df = pd.DataFrame(columns=['person','description','token_description','content','token_content'])\n",
    "person = []\n",
    "description = []\n",
    "p_description = []\n",
    "content = []\n",
    "p_content = []\n",
    "label_2 = []\n",
    "label_6 = []\n",
    "\n",
    "for cat,v in data.items():\n",
    "    for keyw,articles in v.items():\n",
    "        for art in articles:\n",
    "            person.append(art['title'])\n",
    "            description.append(art['description'])\n",
    "            p_description.append(art['p_description'])\n",
    "            content.append(art['content'])\n",
    "            p_content.append(art['p_content'])\n",
    "            \n",
    "            label_2.append(cat)\n",
    "            label_6.append(keyw)\n",
    "\n",
    "p_data = dict(person=person,\n",
    "description=description,\n",
    "p_description=p_description,\n",
    "content=content,\n",
    "p_content=p_content,\n",
    "label_2=label_2,\n",
    "label_6=label_6)\n",
    "\n",
    "len(p_data['p_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              person                                        description  \\\n",
       "0    Kichka_Bodurova                        Bulgarian pop-folk musician   \n",
       "1      Taras_Topolya                                   Ukrainian singer   \n",
       "2     Louis_Graveure  English actor and baritone singer known as \"Th...   \n",
       "3  Philippe_Robrecht                       Belgian guitarist and singer   \n",
       "4      Moira_Lambert                                     British singer   \n",
       "\n",
       "                                       p_description  \\\n",
       "0                     [bulgarian, popfolk, musician]   \n",
       "1                                [ukrainian, singer]   \n",
       "2  [english, actor, baritone, singer, known, myst...   \n",
       "3                       [belgian, guitarist, singer]   \n",
       "4                                  [british, singer]   \n",
       "\n",
       "                                             content  \\\n",
       "0  Big Brother: All-Stars, also known as Big Brot...   \n",
       "1  EdCamp Ukraine (Ukrainian: ЕдКемп Україна) is ...   \n",
       "2  The Accusing Song (German: Ein Lied klagt an) ...   \n",
       "3  Jacques Romain Georges Brel (French: [ʒɑk ʁɔmɛ...   \n",
       "4  Mary Rose Byrne (born 24 July 1979) is an Aust...   \n",
       "\n",
       "                                           p_content label_2 label_6  \n",
       "0  [[big, brother, allstars, also, known, big, br...       A  singer  \n",
       "1  [[edcamp, ukraine, ukrainian, едкемп, україна,...       A  singer  \n",
       "2  [[accusing, song, german, ein, lied, klagt, 19...       A  singer  \n",
       "3  [[jacques, romain, georges, brel, french, ʒɑk,...       A  singer  \n",
       "4  [[mary, rose, byrne, born, 24, july, 1979, aus...       A  singer  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>person</th>\n      <th>description</th>\n      <th>p_description</th>\n      <th>content</th>\n      <th>p_content</th>\n      <th>label_2</th>\n      <th>label_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kichka_Bodurova</td>\n      <td>Bulgarian pop-folk musician</td>\n      <td>[bulgarian, popfolk, musician]</td>\n      <td>Big Brother: All-Stars, also known as Big Brot...</td>\n      <td>[[big, brother, allstars, also, known, big, br...</td>\n      <td>A</td>\n      <td>singer</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Taras_Topolya</td>\n      <td>Ukrainian singer</td>\n      <td>[ukrainian, singer]</td>\n      <td>EdCamp Ukraine (Ukrainian: ЕдКемп Україна) is ...</td>\n      <td>[[edcamp, ukraine, ukrainian, едкемп, україна,...</td>\n      <td>A</td>\n      <td>singer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Louis_Graveure</td>\n      <td>English actor and baritone singer known as \"Th...</td>\n      <td>[english, actor, baritone, singer, known, myst...</td>\n      <td>The Accusing Song (German: Ein Lied klagt an) ...</td>\n      <td>[[accusing, song, german, ein, lied, klagt, 19...</td>\n      <td>A</td>\n      <td>singer</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Philippe_Robrecht</td>\n      <td>Belgian guitarist and singer</td>\n      <td>[belgian, guitarist, singer]</td>\n      <td>Jacques Romain Georges Brel (French: [ʒɑk ʁɔmɛ...</td>\n      <td>[[jacques, romain, georges, brel, french, ʒɑk,...</td>\n      <td>A</td>\n      <td>singer</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Moira_Lambert</td>\n      <td>British singer</td>\n      <td>[british, singer]</td>\n      <td>Mary Rose Byrne (born 24 July 1979) is an Aust...</td>\n      <td>[[mary, rose, byrne, born, 24, july, 1979, aus...</td>\n      <td>A</td>\n      <td>singer</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df = pd.DataFrame(p_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['A','Z']\n",
    "keywords = ['architect', 'mathematician', 'painter', 'politician', 'singer', 'writer']\n",
    "\n",
    "df['label_2'] = df['label_2'].replace(categories,[n for n in range(len(categories))])\n",
    "df['label_6'] = df['label_6'].replace(keywords,[n for n in range(len(keywords))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}