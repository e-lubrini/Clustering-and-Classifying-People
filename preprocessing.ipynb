{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Preprocessing\n",
    "* For each Wikipedia text and Wikidata description collected:\n",
    "\n",
    "    tokenise the text, lowercase the tokens, remove function words\n",
    "\n",
    "* Store the results in a pandas dataframe containing 5 columns:\n",
    "\n",
    "    person, Wikipedia page text, Wikipedia page text after preprocessing, Wikidata description, Wikidata description after preprocessing\n",
    "\n",
    "Note. To improve clustering and classification results, feel free to\n",
    "add further pre-processing steps (eg Named entity recognition, postagging and extraction of e.g., nouns and verbs)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/elisa/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_tokenize(string):\n",
    "    # Sentence splitting\n",
    "    sentences = nltk.sent_tokenize(string)\n",
    "    \n",
    "    # tokenizing \n",
    "    tokenised_s = list(map(nltk.word_tokenize, sentences))\n",
    "\n",
    "    return tokenised_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    \n",
    "    # tokenizing \n",
    "    tokenised_s = nltk.word_tokenize(sent)\n",
    "\n",
    "    #print('Tokenised:', tokenised_s)\n",
    "\n",
    "    return tokenised_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a translation table that maps each punctuation sign to the empty string\n",
    "punct_removed = str.maketrans('','',string.punctuation)\n",
    "\n",
    "# Define a function which segments, tokenizes and removes punctuation signs\n",
    "def tokenize_no_punct(s):\n",
    "    \n",
    "    s = s.translate(punct_removed)\n",
    "\n",
    "    # tokenizing \n",
    "    tokenised_s = segment_and_tokenize(s)\n",
    "\n",
    "    #print('Tokenised without punctuation:', tokenised_s[:10])\n",
    "\n",
    "    return tokenised_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case tokens and remove punctuation\n",
    "\n",
    "def lower_case(c):\n",
    "    return tokenize_no_punct(c.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove function words\n",
    "\n",
    "def preprocess(c):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    lower_s = lower_case(c)\n",
    "\n",
    "    no_stopw_c = [t for s in lower_s for t in s if t not in stop_words]\n",
    "\n",
    "    #print('Preprocessed: ', no_stopw_c[:10])\n",
    "\n",
    "    return no_stopw_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "d', 'chebysheff', 'chebychov', 'chebyshov'], ['tchebychev', 'tchebycheff', 'french', 'transcriptions'], ['tschebyschev', 'tschebyschef', 'tschebyscheff', 'german', 'transcriptions'], ['rarely', 'čebyčev'], ['chebychev', 'mixture', 'english', 'french', 'transliterations', 'sometimes', 'erroneously', 'used']]\n[['varāhamihira', 'c', '505', '–', 'c', '587', 'also', 'called', 'varāha', 'mihira', 'hindu', 'astrologer', 'astronomer', 'polymath', 'lived', 'ujjain', 'madhya', 'pradesh', 'india'], ['born', 'avanti', 'region', 'roughly', 'corresponding', 'modernday', 'malwa', 'part', 'madhya', 'pradesh', 'india', 'adityadasa'], ['according', 'one', 'works', 'educated', 'kapitthaka'], ['indian', 'tradition', 'believes', 'one', 'nine', 'jewels', 'navaratnas', 'court', 'ruler', 'yashodharman', 'vikramaditya', 'malwa'], ['however', 'claim', 'appears', 'first', 'time', 'much', 'later', 'text', 'scholars', 'consider', 'claim', 'doubtful', 'neither', 'varahamihira', 'vikramaditya', 'lived', 'century', 'varahamihira', 'live', 'century', 'names', 'nine', 'jewels', 'list', 'much', 'older', 'kalidasa'], ['varāhamihiras', 'notable', 'work', 'brihat', 'samhita', 'encyclopedic', 'work', 'architecture', 'temples', 'planetary', 'motions', 'eclipses', 'timekeeping', 'astrology', 'seasons', 'cloud', 'formation', 'rainfall', 'agriculture', 'mathematics', 'gemology', 'perfumes', 'many', 'topics'], ['according', 'varahamihira', 'verses', 'merely', 'summarizing', 'earlier', 'existing', 'literature', 'astronomy', 'shilpa', 'sastra', 'temple', 'architecture', 'yet', 'presentation', 'different', 'theories', 'models', 'design', 'among', 'earliest', 'texts', 'survived'], ['chapters', 'brihat', 'samhita', 'verses', 'varahamihira', 'quoted', 'persian', 'traveler', 'scholar', 'al', 'biruni'], ['varāhamihira', 'also', 'credited', 'writing', 'several', 'authoritative', 'texts', 'astronomy', 'astrology'], ['learned', 'greek', 'language', 'praised', 'greeks', 'yavanas', 'text', 'well', 'trained', 'sciences']]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['nicole',\n",
       " 'rachel',\n",
       " 'nikki',\n",
       " 'yanofsky',\n",
       " 'born',\n",
       " 'february',\n",
       " '8',\n",
       " '1994',\n",
       " 'jazzpop',\n",
       " 'singer',\n",
       " 'montreal',\n",
       " 'quebec']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for cat,v in data.items():\n",
    "    for keyw,articles in v.items():\n",
    "        for art in articles:\n",
    "            art['p_sentences'] = []\n",
    "            art['p_description'] = preprocess(art['description'])\n",
    "            for sent in art['sentences']:\n",
    "                art['p_sentences'].append(preprocess(sent))\n",
    "\n",
    "data['A']['singer'][0]['p_sentences'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " 'Z',\n",
       " 'Z',\n",
       " 'Z',\n",
       " 'Z',\n",
       " 'Z',\n",
       " 'Z',\n",
       " 'Z',\n",
       " 'Z',\n",
       " 'Z']"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# store in a dataframe\n",
    "#df = pd.DataFrame(columns=['person','description','token_description','content','token_content'])\n",
    "person = []\n",
    "description = []\n",
    "p_description = []\n",
    "sentences = []\n",
    "p_sentences = []\n",
    "category = []\n",
    "\n",
    "for cat,v in data.items():\n",
    "    for keyw,articles in v.items():\n",
    "        for art in articles:\n",
    "            person.append(art['title'])\n",
    "            description.append(art['description'])\n",
    "            p_description.append(art['p_description'])\n",
    "            sentences.append(art['sentences'])\n",
    "            p_sentences.append(art['p_sentences'])\n",
    "            category.append(cat)\n",
    "\n",
    "p_data = dict(person=person,\n",
    "description=description,\n",
    "p_description=p_description,\n",
    "sentences=sentences,\n",
    "p_sentences=p_sentences,\n",
    "category=category)\n",
    "\n",
    "p_data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           person                                        description  \\\n",
       "0  Nikki Yanofsky  Nicole Rachel \"Nikki\" Yanofsky (born February ...   \n",
       "1       Karna Das  Karna Das (Nepali: कर्ण दास) (born 24 November...   \n",
       "2  Joseph Schmidt  Joseph Schmidt (March 4, 1904 – November 16, 1...   \n",
       "3  Frances Brooke  Frances Brooke (née Moore; 12 January 1724 – 2...   \n",
       "4   Henri Michaux  Henri Michaux (French: [miʃo]; 24 May 1899 – 1...   \n",
       "\n",
       "                                       p_description  \\\n",
       "0  [nicole, rachel, nikki, yanofsky, born, februa...   \n",
       "1  [karna, das, nepali, कर्ण, दास, born, 24, nove...   \n",
       "2  [joseph, schmidt, march, 4, 1904, –, november,...   \n",
       "3  [frances, brooke, née, moore, 12, january, 172...   \n",
       "4  [henri, michaux, french, miʃo, 24, may, 1899, ...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Nicole Rachel \"Nikki\" Yanofsky (born February...   \n",
       "1  [Karna Das (Nepali:, कर्ण दास) (born 24 Novemb...   \n",
       "2  [Joseph Schmidt (March 4, 1904 – November 16, ...   \n",
       "3  [Frances Brooke (née Moore;, 12 January 1724 –...   \n",
       "4  [Henri Michaux (French: [, miʃo];, 24 May 1899...   \n",
       "\n",
       "                                         p_sentences category  \n",
       "0  [[nicole, rachel, nikki, yanofsky, born, febru...        A  \n",
       "1  [[karna, das, nepali], [कर्ण, दास, born, 24, n...        A  \n",
       "2  [[joseph, schmidt, march, 4, 1904, –, november...        A  \n",
       "3  [[frances, brooke, née, moore], [12, january, ...        A  \n",
       "4  [[henri, michaux, french], [miʃo], [24, may, 1...        A  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>person</th>\n      <th>description</th>\n      <th>p_description</th>\n      <th>sentences</th>\n      <th>p_sentences</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Nikki Yanofsky</td>\n      <td>Nicole Rachel \"Nikki\" Yanofsky (born February ...</td>\n      <td>[nicole, rachel, nikki, yanofsky, born, februa...</td>\n      <td>[Nicole Rachel \"Nikki\" Yanofsky (born February...</td>\n      <td>[[nicole, rachel, nikki, yanofsky, born, febru...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Karna Das</td>\n      <td>Karna Das (Nepali: कर्ण दास) (born 24 November...</td>\n      <td>[karna, das, nepali, कर्ण, दास, born, 24, nove...</td>\n      <td>[Karna Das (Nepali:, कर्ण दास) (born 24 Novemb...</td>\n      <td>[[karna, das, nepali], [कर्ण, दास, born, 24, n...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Joseph Schmidt</td>\n      <td>Joseph Schmidt (March 4, 1904 – November 16, 1...</td>\n      <td>[joseph, schmidt, march, 4, 1904, –, november,...</td>\n      <td>[Joseph Schmidt (March 4, 1904 – November 16, ...</td>\n      <td>[[joseph, schmidt, march, 4, 1904, –, november...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Frances Brooke</td>\n      <td>Frances Brooke (née Moore; 12 January 1724 – 2...</td>\n      <td>[frances, brooke, née, moore, 12, january, 172...</td>\n      <td>[Frances Brooke (née Moore;, 12 January 1724 –...</td>\n      <td>[[frances, brooke, née, moore], [12, january, ...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Henri Michaux</td>\n      <td>Henri Michaux (French: [miʃo]; 24 May 1899 – 1...</td>\n      <td>[henri, michaux, french, miʃo, 24, may, 1899, ...</td>\n      <td>[Henri Michaux (French: [, miʃo];, 24 May 1899...</td>\n      <td>[[henri, michaux, french], [miʃo], [24, may, 1...</td>\n      <td>A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "df = pd.DataFrame(p_data)\n",
    "df.head()"
   ]
  }
 ]
}